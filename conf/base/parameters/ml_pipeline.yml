# Comprehensive ML Pipeline Parameters Configuration

# ==========================================
# COMPREHENSIVE TABULAR MODELS
# ==========================================
tabular_models:
  target_column: "gfp_status"  # Actual target column name
  exclude_columns: ["gfp_status", "sample_name", "roi_name"]

  # Random Forest parameters
  rf_n_estimators: 200
  rf_max_depth: 15
  rf_min_samples_split: 5
  rf_min_samples_leaf: 2

  # XGBoost parameters
  xgb_n_estimators: 200
  xgb_max_depth: 8
  xgb_learning_rate: 0.1
  xgb_subsample: 0.8
  xgb_colsample_bytree: 0.8

  # LightGBM parameters
  lgb_n_estimators: 200
  lgb_max_depth: 8
  lgb_learning_rate: 0.1
  lgb_subsample: 0.8
  lgb_colsample_bytree: 0.8

# ==========================================
# COMPREHENSIVE IMAGE MODELS
# ==========================================
image_models:
  num_classes: 2
  batch_size: 32
  max_epochs: 2  # For testing purposes
  learning_rate: 0.001
  image_size: [224, 224]
  pos_weight: 11.27  # For class imbalance

# ==========================================
# COMPREHENSIVE XAI CONFIGURATION
# ==========================================
xai:
  n_samples: 10  # Number of test samples to explain
  save_visualizations: true
  methods:
    - vanilla_saliency
    - guided_backprop
    - deeplift
    - integrated_gradients
    - smoothgrad
    - gradcam

# ==========================================
# LEGACY CONFIGURATIONS (BACKWARD COMPATIBILITY)
# ==========================================

# Tabular model parameters (legacy)
tabular_model:
  target_column: "gfp_status"
  model_type: "xgboost"
  models:
    xgboost:
      n_estimators: 100
      max_depth: 6
      learning_rate: 0.1
      subsample: 0.8
      colsample_bytree: 0.8
      scale_pos_weight: 11.27  # Handle class imbalance (neg/pos ratio)
      random_state: 42

    lightgbm:
      n_estimators: 100
      max_depth: 6
      learning_rate: 0.1
      subsample: 0.8
      colsample_bytree: 0.8
      scale_pos_weight: 11.27  # Handle class imbalance
      random_state: 42

    random_forest:
      n_estimators: 100
      max_depth: 10
      min_samples_split: 5
      min_samples_leaf: 2
      class_weight: "balanced"  # Handle class imbalance
      random_state: 42

# Image model parameters (legacy)
image_model:
  model_type: "resnet18"
  models:
    resnet18:
      pretrained: true
      num_classes: 2
      learning_rate: 0.001
      batch_size: 32
      epochs: 10
      pos_weight: 11.27  # Handle class imbalance
      use_class_weights: true
      loss_function: "focal"  # Better for imbalanced data
      focal_alpha: 0.25
      focal_gamma: 2.0

    cnn:
      num_classes: 2
      learning_rate: 0.001
      batch_size: 32
      epochs: 10
      pos_weight: 11.27  # Handle class imbalance
      use_class_weights: true
      loss_function: "focal"  # Better for imbalanced data
      focal_alpha: 0.25
      focal_gamma: 2.0

# Hyperparameter optimization parameters
optimization:
  framework: 'optuna'
  n_trials: 3  # Reduced for faster testing
  direction: 'maximize'
  metric: 'f1_score'
  target_column: "gfp_status"
  model_type: "xgboost"

# Model comparison parameters
model_comparison:
  metrics:
    - 'accuracy'
    - 'precision'
    - 'recall'
    - 'f1_score'
    - 'roc_auc'

# Deployment parameters
deployment:
  model_format: 'pickle'
  include_preprocessing: false  # No preprocessing needed
  versioning: true

# Artifacts parameters
artifacts:
  save_models: true
  save_metrics: true
  save_explanations: true